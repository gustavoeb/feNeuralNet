//
// Developed by Gustavo E. Boehs
//
/**
This transfer functions are relevant for squashing values
in a non linear fashion.

Known issues:
* softmax layer overflows with high values

*/

/// Hyperbolic tangent sigmoid transfer function
/// \dfgPresetOmit
function Scalar tansig(io Scalar inputs) {
  inputs = 2/(1+exp(-2*inputs))-1;
  return inputs;
}

/// \dfgPresetOmit
function Float64 tansig(io Float64 inputs) {
  inputs = 2/(1+exp(-2*inputs))-1;
  return inputs;
}

/// \dfgPresetOmit
function Scalar[] tansig(io Scalar inputs[]) {
  for(Size i=0; i<inputs.size(); i++){
    inputs[i] = tansig(inputs[i]);
  }
  return inputs;
}

/// \dfgPresetOmit
function Float64[] tansig(io Float64 inputs[]) {
  for(Size i=0; i<inputs.size(); i++){
    inputs[i] = tansig(inputs[i]);
  }
  return inputs;
}

/// Hyperbolic logistic sigmoid transfer function
/// \dfgPresetOmit
function Scalar logsig(io Scalar inputs) {
  inputs = 1 / (1 + exp(-inputs));
  return inputs;
}

/// \dfgPresetOmit
function Float64 logsig(io Float64 inputs) {
  inputs = 1 / (1 + exp(-inputs));
  return inputs;
}

/// \dfgPresetOmit
function Scalar[] logsig(io Scalar inputs[]) {
  for(Size i=0; i<inputs.size(); i++){
    inputs[i] = logsig(inputs[i]);
  }
  return inputs;
}

/// \dfgPresetOmit
function Float64[] logsig(io Float64 inputs[]) {
  for(Size i=0; i<inputs.size(); i++){
    inputs[i] = logsig(inputs[i]);
  }
  return inputs;
}

/// Softmax transfer function
function Scalar[] softmax(io Scalar input[]) {
  Float64 sum;
  Float64 input64; // we need extra precision in this operation

  for(Size i=0; i<input.size(); i++){
    input64 = input[i];
    sum = sum + exp(input64);
  }
  for(Size i=0; i<input.size(); i++){
    input64 = input[i];
    input[i] = Scalar(exp(input64)/sum);
  }
  return input;
}

/// \dfgPresetOmit
function Float64[] softmax(io Float64 input[]) {
  Float64 sum;
  for(Size i=0; i<input.size(); i++){
    sum = sum + exp(input[i]);
  }
  for(Size i=0; i<input.size(); i++){
    input[i] = Scalar(exp(input[i])/sum);
  }
  return input;
}

/// Softmax transfer function for matrices.
/// \dfgPresetOmit
function Mat softmax(io Mat input) {
  Scalar newValues[];

  for(Size i=0; i<input.cols(); i++) {
    newValues = newValues + softmax(input.getColumn(i));
  }

  Mat newMat(input.cols(),input.rows());
  newMat.setAll(newValues);
  input = newMat.transpose();

  return input;
}

/// \dfgPresetOmit
function Mat_d softmax(io Mat_d input) {
  Float64 newValues[];

  for(Size i=0; i<input.cols(); i++) {
    newValues = newValues + softmax(input.getColumn(i));
  }

  Mat_d newMat(input.cols(),input.rows());
  newMat.setAll(newValues);
  input = newMat.transpose();

  return input;
}

/// Softmax transfer function for matrices.
/// \dfgPresetOmit
function Scalar softmax(io Scalar input) {
  return 1.0;
}

/// \dfgPresetOmit
function Float64 softmax(io Float64 input) {
  return 1.0;
}